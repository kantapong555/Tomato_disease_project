import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.metrics import classification_report, confusion_matrix

# ============================================================
# üéØ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå: ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÑ‡∏î‡πâ)
# ============================================================
DATASET_PATH = "segmented"  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å PlantVillage
IMG_SIZE = (224, 224)       # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏•‡∏Å
BATCH_SIZE = 32
EPOCHS = 20                 # ‡πÄ‡∏ó‡∏£‡∏ô 20 ‡∏£‡∏≠‡∏ö ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô 70%

# Data Augmentation (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏†‡∏≤‡∏û‡∏°‡∏±‡∏ß/‡∏°‡∏µ‡πÄ‡∏á‡∏≤ ‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô)
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,      # ‡∏´‡∏°‡∏∏‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡∏ß
    brightness_range=[0.8, 1.2], # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÅ‡∏™‡∏á‡∏°‡∏≤‡∏Å/‡∏ô‡πâ‡∏≠‡∏¢ (‡πÅ‡∏Å‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏á‡∏≤)
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2    # ‡πÅ‡∏ö‡πà‡∏á 20% ‡πÑ‡∏ß‡πâ‡∏™‡∏≠‡∏ö (Validation Set)
)

val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
train_generator = train_datagen.flow_from_directory(
    DATASET_PATH, target_size=IMG_SIZE, batch_size=BATCH_SIZE,
    class_mode='categorical', subset='training', shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    DATASET_PATH, target_size=IMG_SIZE, batch_size=BATCH_SIZE,
    class_mode='categorical', subset='validation', shuffle=False # ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏≠‡∏ô‡∏ß‡∏±‡∏î‡∏ú‡∏•
)

# ============================================================
# üéØ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN (‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå: ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN)
# ============================================================
# ‡πÉ‡∏ä‡πâ MobileNetV2 (CNN) ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠ (Prototype)
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SIZE+(3,))
base_model.trainable = False 

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(train_generator.num_classes, activation='softmax')
])

model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy']) # ‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å

# ============================================================
# üéØ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏≠‡∏ô AI (‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå: ‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢ TensorFlow)
# ============================================================
print(f"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•... ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Accuracy > 70%")
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS,
    callbacks=[
        EarlyStopping(patience=5, restore_best_weights=True),
        ReduceLROnPlateau(factor=0.2, patience=3)
    ]
)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
os.makedirs("model_ai", exist_ok=True)
model.save("model_ai/tomato_disease_model.h5")
print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

# ============================================================
# üéØ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î (‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå: Accuracy, Precision, Recall, F1)
# ============================================================
print("\nüìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•...")
y_pred = np.argmax(model.predict(val_generator), axis=1)
y_true = val_generator.classes
class_labels = list(val_generator.class_indices.keys())

# 1. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏™‡πà‡∏ö‡∏ó‡∏ó‡∏µ‡πà 4 ‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô)
print("\n" + "="*50)
print("üìù Classification Report (‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå Precision, Recall, F1)")
print("="*50)
print(classification_report(y_true, y_pred, target_names=class_labels))

# 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Accuracy ‡∏£‡∏ß‡∏°
accuracy = np.mean(y_pred == y_true) * 100
print(f"üèÜ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏£‡∏ß‡∏° (Accuracy): {accuracy:.2f}%")
if accuracy > 70:
    print("‚úÖ ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (> 70%)")
else:
    print("‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°")

# ============================================================
# üéØ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î (‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå: Analyze Errors)
# ============================================================
# ‡∏ß‡∏≤‡∏î Confusion Matrix (‡∏î‡∏π‡∏ß‡πà‡∏≤ AI ‡∏™‡∏±‡∏ö‡∏™‡∏ô‡πÇ‡∏£‡∏Ñ‡πÑ‡∏´‡∏ô‡∏Å‡∏±‡∏ö‡πÇ‡∏£‡∏Ñ‡πÑ‡∏´‡∏ô)
plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.title('Confusion Matrix (‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î)')
plt.ylabel('‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á (True)')
plt.xlabel('‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Predicted)')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# ‡∏Å‡∏£‡∏≤‡∏ü Accuracy/Loss (‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÄ‡∏•‡πà‡∏°)
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Accuracy Graph')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss Graph')
plt.legend()
plt.show()